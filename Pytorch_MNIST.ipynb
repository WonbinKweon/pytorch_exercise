{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n",
      "==>>> total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25e7befb0b8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, _ = next(iter(train_loader))\n",
    "img = inputs[4][0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #flat시키기\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "    \n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 1, batch index: 100, train loss: 0.891320\n",
      "==>>> epoch: 1, batch index: 200, train loss: 0.446379\n",
      "==>>> epoch: 1, batch index: 300, train loss: 0.244804\n",
      "==>>> epoch: 1, batch index: 400, train loss: 0.372875\n",
      "==>>> epoch: 1, batch index: 500, train loss: 0.355076\n",
      "==>>> epoch: 1, batch index: 600, train loss: 0.414167\n",
      "88\n",
      "==>>> epoch: 1, batch index: 100, test loss: 0.436909, acc: 0.917\n",
      "==>>> epoch: 2, batch index: 100, train loss: 0.326387\n",
      "==>>> epoch: 2, batch index: 200, train loss: 0.343088\n",
      "==>>> epoch: 2, batch index: 300, train loss: 0.222809\n",
      "==>>> epoch: 2, batch index: 400, train loss: 0.426197\n",
      "==>>> epoch: 2, batch index: 500, train loss: 0.238889\n",
      "==>>> epoch: 2, batch index: 600, train loss: 0.089522\n",
      "94\n",
      "==>>> epoch: 2, batch index: 100, test loss: 0.304139, acc: 0.943\n",
      "==>>> epoch: 3, batch index: 100, train loss: 0.139597\n",
      "==>>> epoch: 3, batch index: 200, train loss: 0.183021\n",
      "==>>> epoch: 3, batch index: 300, train loss: 0.115531\n",
      "==>>> epoch: 3, batch index: 400, train loss: 0.118993\n",
      "==>>> epoch: 3, batch index: 500, train loss: 0.101719\n",
      "==>>> epoch: 3, batch index: 600, train loss: 0.145903\n",
      "96\n",
      "==>>> epoch: 3, batch index: 100, test loss: 0.215764, acc: 0.954\n",
      "==>>> epoch: 4, batch index: 100, train loss: 0.107065\n",
      "==>>> epoch: 4, batch index: 200, train loss: 0.137983\n",
      "==>>> epoch: 4, batch index: 300, train loss: 0.163487\n",
      "==>>> epoch: 4, batch index: 400, train loss: 0.273706\n",
      "==>>> epoch: 4, batch index: 500, train loss: 0.079024\n",
      "==>>> epoch: 4, batch index: 600, train loss: 0.137143\n",
      "95\n",
      "==>>> epoch: 4, batch index: 100, test loss: 0.226143, acc: 0.960\n",
      "==>>> epoch: 5, batch index: 100, train loss: 0.046119\n",
      "==>>> epoch: 5, batch index: 200, train loss: 0.181745\n",
      "==>>> epoch: 5, batch index: 300, train loss: 0.098334\n",
      "==>>> epoch: 5, batch index: 400, train loss: 0.137267\n",
      "==>>> epoch: 5, batch index: 500, train loss: 0.137357\n",
      "==>>> epoch: 5, batch index: 600, train loss: 0.191776\n",
      "97\n",
      "==>>> epoch: 5, batch index: 100, test loss: 0.120645, acc: 0.965\n",
      "==>>> epoch: 6, batch index: 100, train loss: 0.048300\n",
      "==>>> epoch: 6, batch index: 200, train loss: 0.147021\n",
      "==>>> epoch: 6, batch index: 300, train loss: 0.100697\n",
      "==>>> epoch: 6, batch index: 400, train loss: 0.228911\n",
      "==>>> epoch: 6, batch index: 500, train loss: 0.089960\n",
      "==>>> epoch: 6, batch index: 600, train loss: 0.114638\n",
      "97\n",
      "==>>> epoch: 6, batch index: 100, test loss: 0.104169, acc: 0.969\n",
      "==>>> epoch: 7, batch index: 100, train loss: 0.039617\n",
      "==>>> epoch: 7, batch index: 200, train loss: 0.069120\n",
      "==>>> epoch: 7, batch index: 300, train loss: 0.112372\n",
      "==>>> epoch: 7, batch index: 400, train loss: 0.101372\n",
      "==>>> epoch: 7, batch index: 500, train loss: 0.052998\n",
      "==>>> epoch: 7, batch index: 600, train loss: 0.082534\n",
      "96\n",
      "==>>> epoch: 7, batch index: 100, test loss: 0.104182, acc: 0.972\n",
      "==>>> epoch: 8, batch index: 100, train loss: 0.091161\n",
      "==>>> epoch: 8, batch index: 200, train loss: 0.035446\n",
      "==>>> epoch: 8, batch index: 300, train loss: 0.032781\n",
      "==>>> epoch: 8, batch index: 400, train loss: 0.059911\n",
      "==>>> epoch: 8, batch index: 500, train loss: 0.059284\n",
      "==>>> epoch: 8, batch index: 600, train loss: 0.043011\n",
      "99\n",
      "==>>> epoch: 8, batch index: 100, test loss: 0.059160, acc: 0.971\n",
      "==>>> epoch: 9, batch index: 100, train loss: 0.061693\n",
      "==>>> epoch: 9, batch index: 200, train loss: 0.054940\n",
      "==>>> epoch: 9, batch index: 300, train loss: 0.079415\n",
      "==>>> epoch: 9, batch index: 400, train loss: 0.045677\n",
      "==>>> epoch: 9, batch index: 500, train loss: 0.123261\n",
      "==>>> epoch: 9, batch index: 600, train loss: 0.071829\n",
      "99\n",
      "==>>> epoch: 9, batch index: 100, test loss: 0.046393, acc: 0.975\n"
     ]
    }
   ],
   "source": [
    "model = MLPNet()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    # trainning\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        \n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "                epoch, batch_idx+1, loss,data))\n",
    "            \n",
    "    # testing\n",
    "    correct_cnt = 0\n",
    "    total_cnt= 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            if use_cuda:\n",
    "                x, target = x.cuda(), target.cuda()\n",
    "            x, target = Variable(x), Variable(target)\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = criterion(out, target)\n",
    "            _, pred_label = torch.max(out.data, 1)\n",
    "            total_cnt = total_cnt + batch_size\n",
    "            count = torch.sum(pred_label == target.data)\n",
    "            \n",
    "            correct_cnt = correct_cnt + count.item()\n",
    "            if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "                print('==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                    epoch, batch_idx+1, loss.data , correct_cnt * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
